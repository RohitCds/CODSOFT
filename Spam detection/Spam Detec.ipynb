{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c1c1f7",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2470ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163100d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read the file with encoding: utf-8\n",
      "File read successfully with encoding: ISO-8859-1\n"
     ]
    }
   ],
   "source": [
    "encodings = ['utf-8', 'ISO-8859-1', 'cp1252']\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        data = pd.read_csv(\"C:\\\\Users\\\\rohit\\\\OneDrive\\\\Desktop\\\\Codsoft 2\\\\Spam detection\\\\spam.csv\", encoding=encoding)\n",
    "        print(\"File read successfully with encoding:\", encoding)\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Failed to read the file with encoding:\", encoding)\n",
    "#We try specifying a different encoding when reading the CSV file. Common alternatives to UTF-8 include 'ISO-8859-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0542f1",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e8a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e20e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\rohit\\\\OneDrive\\\\Desktop\\\\Codsoft 2\\\\Spam detection\\\\spam.csv\", encoding=\"ISO-8859-1\")\n",
    "print(data.head())\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['v1'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['label'], test_size=0.2, random_state=42)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6c0ca1",
   "metadata": {},
   "source": [
    "The above code performs the following data processing steps:\n",
    "\n",
    "1. Load the dataset using pandas.\n",
    "\n",
    "2. Convert the categorical labels (ham/spam) to numerical format (0/1) using LabelEncoder.\n",
    "\n",
    "3. Split the dataset into training and testing sets.\n",
    "\n",
    "4. Perform TF-IDF vectorization on the text data using scikit-learn's TfidfVectorizer.\n",
    "\n",
    "5. Print the shapes of the TF-IDF matrices for both the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca94b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has some additional columns (Unnamed: 2, Unnamed: 3, Unnamed: 4) that don't contain any useful information.\n",
    "data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006cd953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  label\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
       "1   ham                      Ok lar... Joking wif u oni...      0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3   ham  U dun say so early hor... U c already then say...      0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e402d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V1 too can be dropped since we have already converted it to numerical form required by the model in \"label\".\n",
    "data.drop('v1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba3c07",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a41b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['v2'], data['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4914192",
   "metadata": {},
   "source": [
    "### We start with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd65214",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "naive_bayes_classifier.fit(X_train_tfidf, y_train)\n",
    "nb_predictions = naive_bayes_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a5249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Performance:\n",
      "Accuracy: 0.9668161434977578\n",
      "Precision: 1.0\n",
      "Recall: 0.7533333333333333\n",
      "F1-score: 0.8593155893536121\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the performance\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_precision = precision_score(y_test, nb_predictions)\n",
    "nb_recall = recall_score(y_test, nb_predictions)\n",
    "nb_f1 = f1_score(y_test, nb_predictions)\n",
    "\n",
    "print(\"Naive Bayes Classifier Performance:\")\n",
    "print(\"Accuracy:\", nb_accuracy)\n",
    "print(\"Precision:\", nb_precision)\n",
    "print(\"Recall:\", nb_recall)\n",
    "print(\"F1-score:\", nb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25a01c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1570609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_classifier = LogisticRegression(max_iter=1000)\n",
    "logistic_regression_classifier.fit(X_train_tfidf, y_train)\n",
    "lr_predictions = logistic_regression_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1633285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classifier Performance:\n",
      "Accuracy: 0.9524663677130045\n",
      "Precision: 0.970873786407767\n",
      "Recall: 0.6666666666666666\n",
      "F1-score: 0.7905138339920948\n"
     ]
    }
   ],
   "source": [
    "#Evaluating its performance\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_precision = precision_score(y_test, lr_predictions)\n",
    "lr_recall = recall_score(y_test, lr_predictions)\n",
    "lr_f1 = f1_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"\\nLogistic Regression Classifier Performance:\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"Precision:\", lr_precision)\n",
    "print(\"Recall:\", lr_recall)\n",
    "print(\"F1-score:\", lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555fa0e",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac21c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f3ad8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine Classifier Performance:\n",
      "Accuracy: 0.9766816143497757\n",
      "Precision: 0.9920634920634921\n",
      "Recall: 0.8333333333333334\n",
      "F1-score: 0.9057971014492753\n"
     ]
    }
   ],
   "source": [
    "#Evaluating its performance\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_precision = precision_score(y_test, svm_predictions)\n",
    "svm_recall = recall_score(y_test, svm_predictions)\n",
    "svm_f1 = f1_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"\\nSupport Vector Machine Classifier Performance:\")\n",
    "print(\"Accuracy:\", svm_accuracy)\n",
    "print(\"Precision:\", svm_precision)\n",
    "print(\"Recall:\", svm_recall)\n",
    "print(\"F1-score:\", svm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd92b4",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84f27d",
   "metadata": {},
   "source": [
    "Now we write the final code that compares their accuracies and prints which one is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa709cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Performance:\n",
      "Accuracy: 0.9668161434977578\n",
      "\n",
      "Logistic Regression Classifier Performance:\n",
      "Accuracy: 0.9524663677130045\n",
      "\n",
      "Support Vector Machine Classifier Performance:\n",
      "Accuracy: 0.9766816143497757\n",
      "\n",
      "The best performing classifier is: Support Vector Machine with accuracy: 0.9766816143497757\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Classifier Performance:\")\n",
    "print(\"Accuracy:\", nb_accuracy)\n",
    "print(\"\\nLogistic Regression Classifier Performance:\")\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "print(\"\\nSupport Vector Machine Classifier Performance:\")\n",
    "print(\"Accuracy:\", svm_accuracy)\n",
    "\n",
    "\n",
    "best_classifier = max([(nb_accuracy, \"Naive Bayes\"), (lr_accuracy, \"Logistic Regression\"), (svm_accuracy, \"Support Vector Machine\")])\n",
    "best_accuracy, best_classifier_name = best_classifier\n",
    "\n",
    "print(\"\\nThe best performing classifier is:\", best_classifier_name, \"with accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e188fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
